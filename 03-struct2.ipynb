{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grains, molecules, atoms\n",
    "\n",
    "```\n",
    " +- grains\n",
    "    +- grain_states [each line has a corresponding grain_XXXXX group]\n",
    "    +- grain_0001\n",
    "       +- molecule_states [each line has a corresponding molecule_XXXXX group]\n",
    "       +- molecule_0001\n",
    "          +- atom_states [one per line]\n",
    "       +- molecule_0002\n",
    "          +- atom_states\n",
    "    +- grain_0002\n",
    "       +- molecule_states\n",
    "       +- molecule_0001\n",
    "          +- atom_states \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following will be later probably stored as JSON\n",
    "# only dicts and lists allowed (though not checked, currently)\n",
    "\n",
    "grainJson={\n",
    "    '_schema':'grain',\n",
    "    'identity':{\n",
    "        'material':{'dtype':'a','shape':'variable'}\n",
    "    },\n",
    "    'properties':{\n",
    "        'eletrical':{\n",
    "            'freeElectrons':{'dtype':'l','unit':'none'},\n",
    "            'freeHoles':{'dtype':'l','unit':'none'},\n",
    "        },\n",
    "        'physical':{\n",
    "            'reorganizationEnergyExternal':{'dtype':'d','unit':'eV'}\n",
    "        },\n",
    "        'chemical':{},\n",
    "    },\n",
    "    'topology':{\n",
    "        'parent':{'dtype':'l'},\n",
    "        'cellSize':{'dtype':'d','shape':[3],'unit':'m'},\n",
    "    },\n",
    "    'implementation':{\n",
    "        'boundaryCondition':{'dtype':'a'}\n",
    "    },\n",
    "    'molecules':{'path':'grain_{ROW}/molecules','schema':'molecule'}\n",
    "}\n",
    "\n",
    "moleculeJson={\n",
    "    '_schema':'molecule',\n",
    "    'identity':{\n",
    "        'chemicalName':{'dtype':'a','shape':'variable'},\n",
    "        'molecularWeight':{'dtype':'d','unit':'Dalton'},\n",
    "    },\n",
    "    'properties':{\n",
    "        'electrical':{\n",
    "            'HOMO':{'dtype':'d','unit':'eV'},\n",
    "            'LUMO':{'dtype':'d','unit':'eV'},\n",
    "            'siteEnergy':{\n",
    "                'orbital':{'dtype':'d','unit':'eV'},\n",
    "                'electrostatic':{'dtype':'d','unit':'eV'},\n",
    "                'polarization':{'dtype':'d','unit':'eV'},\n",
    "            },\n",
    "            'transferIntegrals':{'dtype':'d','shape':'variable'},\n",
    "            'reorganizationEnergyInternal':{\n",
    "                'anion':{'dtype':'d','unit':'eV'},\n",
    "                'cation':{'dtype':'d','unit':'eV'}\n",
    "            },\n",
    "        },\n",
    "        'physical':{\n",
    "            'polarizability':{\n",
    "                'neutral':{'dtype':'d','shape':[3,3],'unit':'AA^2 s^4 kg^-1'},\n",
    "                'anion':{'dtype':'d','shape':[3,3],'unit':'AA^2 s^4 kg^-1'},\n",
    "                'cation':{'dtype':'d','shape':[3,3],'unit':'AA^2 s^4 kg^-1'},\n",
    "            }\n",
    "        },\n",
    "        'chemical':{},\n",
    "    },\n",
    "    'topology':{\n",
    "        'parent':{'dtype':'l','unit':'none'},\n",
    "        'centerOfMass':{'dtype':'d','shape':[3],'unit':'AA'},\n",
    "        'symmetryAxis':{'dtype':'d','shape':[3],'unit':'AA'},\n",
    "        'structureNeighbors':{'dtype':'l','shape':'variable'},\n",
    "    },\n",
    "    'implementation':{\n",
    "        'forceFieldType':{'dtype':'a','shape':'variable'},\n",
    "    },\n",
    "    'atoms':{'path':'molecule_{ROW}/atoms','schema':'atom'}\n",
    "}\n",
    "atomJson={\n",
    "    '_schema':'atom',\n",
    "    'identity':{\n",
    "        'element':{'dtype':'a2'}, # 2 characters ascii\n",
    "        # inherent property: values stored in the schema and looked up on-demand\n",
    "        'atomicNumber':{'dtype':'l','key':'identity.element','lookup':{'H':1,'C':12}},\n",
    "        'atomicMass':{'dtype':'d','unit':'Dalton'},\n",
    "    },\n",
    "    'properties':{\n",
    "        'physical':{\n",
    "            'partialCharge':{\n",
    "                'neutral': {'dtype':'d','unit':'e'},\n",
    "                'anion': {'dtype':'d','unit':'e'},\n",
    "                'cation': {'dtype':'d','unit':'e'},\n",
    "            },\n",
    "            'polarizability':{\n",
    "                'neutral': {'dtype':'d','unit':'AA^2 s^4 kg^-1'},\n",
    "                'anion': {'dtype':'d','unit':'AA^2 s^4 kg^-1'},\n",
    "                'cation': {'dtype':'d','unit':'AA^2 s^4 kg^-1'},\n",
    "            }\n",
    "        },\n",
    "        'topology':{\n",
    "            'parent':{'dtype':'l'},\n",
    "            'type':{'dtype':'a','shape':'variable'},\n",
    "            'name':{'dtype':'a','shape':'variable'},\n",
    "            'position':{'dtype':'d','shape':[3],'unit':'AA'},\n",
    "            'velocity':{'dtype':'d','shape':[3],'unit':'AA/ps'},\n",
    "            'structure':{'dtype':'l','shape':'variable'},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dtype `a`: implies `'shape':'variable'` (`a3`, on the other hand, is fixed-size and does not imply variable length)\n",
    "* dtype `l`: implies `'unit':'none'` (`none` unit is a shorthand for dimensionless unscaled)\n",
    "* `'path'` creates iterator, `{ROW}` will expand to the row index of the parent struct\n",
    "* all items must have `unit` (except of `path`, and cases where it is implied)\n",
    "* item assignment must include units, and the value must be converted to the declared unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable-length: properties.topology.structure\n",
      "variable-length: properties.electrical.transferIntegrals\n",
      "variable-length: topology.structureNeighbors\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import dataclasses\n",
    "import astropy.units\n",
    "import astropy.units as u\n",
    "astropy.units.add_enabled_units([\n",
    "    astropy.units.def_unit('e',astropy.constants.si.e),\n",
    "    astropy.units.def_unit('none',astropy.units.dimensionless_unscaled)\n",
    "])\n",
    "import numpy as np\n",
    "import h5py\n",
    "from pprint import pprint\n",
    "from typing import *\n",
    "\n",
    "    \n",
    "@dataclass\n",
    "class CookedSchemaRef:\n",
    "    path: str\n",
    "    schema: str\n",
    "\n",
    "@dataclass\n",
    "class InherentSchemaElement:\n",
    "    lookup: dict\n",
    "    key: str\n",
    "    # TODO: perhaps also note dtype and shape?\n",
    "    \n",
    "    \n",
    "    \n",
    "@dataclass\n",
    "class CookedSchema:\n",
    "    '''Cooked schema so that it is directly usable by h5py/numpy and DataProxy.\n",
    "    Unfortunately, h5py discards dtype metadata, so units must be stored separately.\n",
    "    Currently it is stored in both places (see NumpyDataProxy._getUnit) but later,\n",
    "    only the seaprate storage will be used.\n",
    "    '''\n",
    "    dtype: Union[List,np.dtype]=dataclasses.field(default_factory=list)\n",
    "    units: dict=dataclasses.field(default_factory=dict)\n",
    "    defaults: dict=dataclasses.field(default_factory=dict)\n",
    "    refs: dict=dataclasses.field(default_factory=dict)\n",
    "    inherent: dict=dataclasses.field(default_factory=dict)\n",
    "    name: str=''\n",
    "    def merge(self,other):\n",
    "        self.dtype+=other.dtype\n",
    "        self.units.update(other.units)\n",
    "        self.defaults.update(other.defaults)\n",
    "        self.inherent.update(other.inherent)\n",
    "\n",
    "def cookSchema(desc,prefix=''):\n",
    "    '''\n",
    "    Transform dictionary-structured data schema into compound cooked data.\n",
    "    The result is used by NumpyDataProxy.\n",
    "    '''\n",
    "    assert isinstance(desc,dict)\n",
    "    ret=CookedSchema()\n",
    "    for k,v in desc.items():\n",
    "        if k[0]=='_':\n",
    "            if k=='_schema': continue # ignore for now\n",
    "        name=prefix+('.' if prefix else '')+k\n",
    "        if 'path' in v:\n",
    "            ret.refs[name]=CookedSchemaRef(path=v['path'],schema=v['schema'])\n",
    "            continue # skip\n",
    "        elif 'lookup' in v:\n",
    "            ret.inherent[name]=InherentSchemaElement(lookup=v['lookup'],key=v['key'])\n",
    "            ret.units[name]=astropy.units.Unit(v['unit']) if 'unit' in v else None\n",
    "        elif 'dtype' in v:\n",
    "            shape=v['shape'] if 'shape' in v else ()\n",
    "            if isinstance(shape,list): shape=tuple(shape)\n",
    "            unit=astropy.units.Unit(v['unit']) if 'unit' in v else None\n",
    "            dtype=v['dtype']\n",
    "            default=None\n",
    "            if dtype=='a':\n",
    "                dtype=h5py.string_dtype(encoding='utf-8')\n",
    "                shape=None\n",
    "            elif shape=='variable':\n",
    "                dtype=h5py.vlen_dtype(np.dtype(dtype))\n",
    "                print(f\"variable-length: {name}\")\n",
    "                shape=None\n",
    "            else:\n",
    "                dtype=np.dtype((dtype,shape))\n",
    "                kind=(dtype.kind if not hasattr(dtype,'subtype') or dtype.subtype is None else dtype.subtype[0].kind)\n",
    "                if kind=='f': default=np.nan\n",
    "                elif kind in 'iu': default=0\n",
    "            ret.dtype+=[(name,dtype)]\n",
    "            ret.units[name]=unit\n",
    "            if default is not None: ret.defaults[name]=default\n",
    "        else:\n",
    "            ret.merge(cookSchema(v,prefix=name))\n",
    "    if prefix: return ret\n",
    "    ret.dtype=np.dtype(ret.dtype)\n",
    "    ret.name=desc['_schema']\n",
    "    for k,v in ret.inherent.items():\n",
    "        if v.key not in ret.units: raise ValueError(f'{k}: lookup key {v.key} does not exist in the schema (must be fully-qualified).')\n",
    "    return ret\n",
    "    #return ret\n",
    "\n",
    "class Hdf5DataProxy(object):\n",
    "    '''\n",
    "    Class for emulating property-like access to compound data type. Values can be both numpy array\n",
    "    or h5py dataset (later, only h5py dataset will be allowed — due to nested data which are not \n",
    "    handled yet).\n",
    "    \n",
    "    With h5py, the dataset can be larger than RAM, as all assignments operate on the storage directly.\n",
    "    \n",
    "    Units are fully supported, i.e. assignments to a value with unit *must* be an astropy.units.Quantity\n",
    "    with compatible units, and values are stored (and returned) using the units specified in the schema.\n",
    "    '''\n",
    "    def __init__(self,group,name,schemaName,schemaRegistry,prefix='',row=None):\n",
    "        self._group=group\n",
    "        self._name=name\n",
    "        self._schemaName=schemaName\n",
    "        self._schemaRegistry=schemaRegistry\n",
    "        self._schema=schemaRegistry[schemaName]\n",
    "        self._leaves=set(self._schema.dtype.names)\n",
    "        self._leaves.update(self._schema.refs.keys())\n",
    "        self._leaves.update(self._schema.inherent.keys())\n",
    "        if self._name in self._group:\n",
    "            # TODO: check schema stored in the dataset attributes for possible mismatch\n",
    "            self._values=self._group[self._name]\n",
    "        else:\n",
    "            # print(f\"Prefix is {prefix}, there is not data for {name}\")\n",
    "            self._values=None\n",
    "        \n",
    "        self._parents=set()\n",
    "        self._row=row\n",
    "        for n in self._leaves:\n",
    "            while '.' in n:\n",
    "                n=n.rsplit('.',1)[0]\n",
    "                self._parents.add(n)\n",
    "        self._prefix=prefix\n",
    "    def _clone(self,key=None,row=None):\n",
    "        'Clone the current object, possibly changing prefix and/or row (created nested accessor)'\n",
    "        if row and self._row: raise IndexError(f'Accessor is already indexed, with row={row}.')\n",
    "        if self._row: row=self._row\n",
    "        if key: prefix=self._getFQ(key)\n",
    "        else: prefix=self._prefix\n",
    "        return self.__class__(\n",
    "            group=self._group,\n",
    "            name=self._name,\n",
    "            schemaName=self._schemaName,\n",
    "            schemaRegistry=self._schemaRegistry,\n",
    "            prefix=prefix,\n",
    "            row=row\n",
    "        )\n",
    "    def _getFQ(self,key):\n",
    "        'Fully-qualified name for the key'\n",
    "        return (f'{self._prefix}.{key}' if self._prefix else key)\n",
    "    def _getUnit(self,fq):\n",
    "        '''Find unit used for the fully-qualified name; numpy could store that in dtype metadata,\n",
    "        but those are discarded in h5py and separate storage in the schema is used.\n",
    "        '''\n",
    "        return self._schema.units.get(fq,None)\n",
    "    def _assertValues(self,msg=''):\n",
    "        if self._values is None: raise RuntimeError(f'Dataset not yet initialized, use _allocate first{\" (\"+msg+\")\" if msg else \"\"}.')\n",
    "    def _allocate(self,size):\n",
    "        if self._values: raise RuntimeError(f'Dataset already exists (shape {self._values.shape}), re-allocation not supported.')\n",
    "        self._values=self._group.create_dataset(self._name,shape=(size,),dtype=self._schema.dtype)\n",
    "        # TODO: store schema JSON into dataset attributes\n",
    "        # set default values, will broadcast to all rows\n",
    "        for k,v in self._schema.defaults.items(): self._values[k]=v\n",
    "    def __getattr__(self,key):\n",
    "        '''\n",
    "        Override standard attribute getter to allow property-like access to the compound data.\n",
    "        Names starting with _ are handled normally (otherwise there would be infinite recursion).\n",
    "        The value returned is either value (for leaf nodes; including units, if defined) or accessor\n",
    "        to the nested category.\n",
    "        '''\n",
    "        if key.startswith('_'):\n",
    "            # if key is invalid, the exception is not legible: type object 'object' has no attribute '__getattr__'\n",
    "            # catch and rethrow with a better message (not the \"from None\" as well)\n",
    "            try: return object.__getattr__(self,key)\n",
    "            except AttributeError: raise AttributeError(f'No such attribute: \"{key}\"') from None\n",
    "        fq=self._getFQ(key)\n",
    "        if fq in self._parents: return self._clone(key=key)\n",
    "        if fq not in self._leaves: raise AttributeError(f\"'{fq}': not such attribute (prefix='{self._prefix}', '{key}')\")\n",
    "        # leaf data access\n",
    "        self._assertValues(msg=f'attempt to read {fq}')\n",
    "        if fq in self._schema.refs:\n",
    "            ref=self._schema.refs[fq]\n",
    "            if '{ROW}' not in ref.path: raise ValueError(f\"'{fq}': schema ref path '{ref.path}' does not contain '{{ROW}}'.\")\n",
    "            if self._row is None: raise AttributeError(f\"'{fq}': row index not set, unable to follow schema ref.\")\n",
    "            self._values[self._row] # this will catch invalid row index, though we won't use the data\n",
    "            path=ref.path.replace('{ROW}',str(self._row))\n",
    "            if '/' not in path: raise ValueError(f\"{fq}: ref path '{ref.path}' does not contain '/'.\")\n",
    "            dir,name=path.rsplit('/',1)\n",
    "            subgrp=self._group.require_group(dir)\n",
    "            # print(f\"{fq}[{self._row}]: subgrp is {subgrp}, rel. path was {dir}/{name}\")\n",
    "            return self.__class__(group=subgrp,name=name,schemaName=ref.schema,schemaRegistry=self._schemaRegistry)\n",
    "        unit=self._getUnit(fq)\n",
    "        if fq in self._schema.inherent:\n",
    "            if self._row is None: raise AttributeError(f\"'{fq}': row index not set, unable to look up inherent value.\")\n",
    "            inh=self._schema.inherent[fq]\n",
    "            k=self._values[inh.key,self._row]\n",
    "            if isinstance(k,bytes): k=k.decode('utf8')\n",
    "            val=inh.lookup[k]\n",
    "            if unit: return astropy.units.Quantity(value=val,unit=unit)\n",
    "            else: return val\n",
    "        if unit:\n",
    "            value=self._values[fq]\n",
    "            if self._row: value=value[row]\n",
    "            return astropy.units.Quantity(value=value,unit=unit)\n",
    "        if self._row: return self._values[fq][self._row]\n",
    "        else: return self._values[fq] \n",
    "    def __setattr__(self,key,val):\n",
    "        '''\n",
    "        Override standard attribute setter to allow modification of data in a property-like manner.\n",
    "        Names starting with _ are handled specially.\n",
    "        Unit consistency is checked during assignment.\n",
    "        If row is not specified, broadcasting will be active (this functionality is provided by both\n",
    "        h5py and numpy), i.e. the whole column will be set.\n",
    "        '''\n",
    "        if key.startswith('_'): return object.__setattr__(self,key,val)\n",
    "        fq=self._getFQ(key=key)\n",
    "        if fq not in self._leaves: raise AttributeError(f\"'{fq}': not such settable attribute (prefix='{self._prefix}', '{key}')\")\n",
    "        if fq in self._schema.refs: raise AttributeError(f\"'{fq}': read-only sub-schema reference (schema '{self._schema.refs[fq].schema}', path '{self._schema.refs[fq].path}').\")    \n",
    "        if fq in self._schema.inherent: raise AttributeError(f\"'{fq}': read-only inherent property (lookup key '{self._schema.inherent[fq].key}').\")    \n",
    "        self._assertValues(msg=f'attempt to write {fq}')\n",
    "        field=self._values.dtype.fields[fq][0]\n",
    "        unit=self._getUnit(fq)\n",
    "        if unit: val2=(astropy.units.Quantity(val).to(unit)).value\n",
    "        else: val2=val\n",
    "        if self._row:\n",
    "            if isinstance(self._values,h5py.Dataset): self._values[self._row,fq]=val2\n",
    "            else: self._values[self._row][fq]=val2\n",
    "        else: self._values[fq]=val2\n",
    "    def __getitem__(self,row): \n",
    "        '''\n",
    "        Indexing access.\n",
    "        Note that the index (row) is only remembered and engaged only when leaf node is read/written.\n",
    "        Thus e.g. foo[2].bar.baz=2 is equal to foo.bar.baz[2]=2.\n",
    "        '''\n",
    "        if self._values is None: raise IndexError(\"Data not allocated yet.\")\n",
    "        if row>=self._values.shape[0]: raise IndexError(f\"Row index outside of the valid range 0…{self._values.shape[0]}.\")\n",
    "        return self._clone(row=row)\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Number of indexable elements\n",
    "        '''\n",
    "        self._assertValues(msg=f'querying data length')\n",
    "        if self._row is not None: return IndexError('Row index already set, not behaving as sequence.')\n",
    "        return self._values.shape[0]\n",
    "    def __dir__(self):\n",
    "        '''\n",
    "        List properties (attributes) available for this accessor.\n",
    "        '''\n",
    "        return set([n[len(self._prefix)+1:].split('.',1)[0] for n in self._values.dtype.names if n.startswith(self._prefix+'.')])\n",
    "        \n",
    "# \"compile\" all schemas and store them in schemaRegistry (used below)\n",
    "schemaRegistry=dict([(schema.name,schema) for schema in [cookSchema(atomJson),cookSchema(moleculeJson),cookSchema(grainJson)]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Hdf5DataProxy object at 0x7f72a086bac0>\n",
      "[b'C' b'C' b'C' b'C' b'C' b'C' b'C' b'C' b'C' b'C']\n",
      "12\n",
      "[[10. 20. 30.]\n",
      " [10. 20. 30.]\n",
      " [10. 20. 30.]\n",
      " [10. 20. 30.]\n",
      " [10. 20. 30.]\n",
      " [10. 20. 30.]\n",
      " [10. 20. 30.]\n",
      " [10. 20. 30.]\n",
      " [10. 20. 30.]\n",
      " [10. 20. 30.]] Angstrom\n",
      "[[0.24 0.05 0.77]\n",
      " [0.24 0.05 0.77]\n",
      " [0.24 0.05 0.77]\n",
      " [0.24 0.05 0.77]\n",
      " [0.24 0.05 0.77]\n",
      " [0.24 0.05 0.77]\n",
      " [0.24 0.05 0.77]\n",
      " [0.24 0.05 0.77]\n",
      " [0.24 0.05 0.77]\n",
      " [0.24 0.05 0.77]] Angstrom / ps\n",
      "['physical', 'topology']\n",
      "<__main__.Hdf5DataProxy object at 0x7f72a086bf40>\n",
      "[0.60221408 0.60221408 0.60221408 0.60221408 0.60221408 0.60221408\n",
      " 0.60221408 0.60221408 0.60221408 0.60221408] u\n",
      "[[10. 20. 30.]\n",
      " [10. 20. 30.]\n",
      " [10. 20. 30.]\n",
      " ...\n",
      " [10. 20. 30.]\n",
      " [10. 20. 30.]\n",
      " [10. 20. 30.]] Angstrom\n",
      "[[0.24 0.05 0.77]\n",
      " [0.24 0.05 0.77]\n",
      " [0.24 0.05 0.77]\n",
      " ...\n",
      " [0.24 0.05 0.77]\n",
      " [0.24 0.05 0.77]\n",
      " [0.24 0.05 0.77]] Angstrom / ps\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('/tmp/test-atom.h5','w') as h5:\n",
    "    atoms=Hdf5DataProxy(group=h5['/'],name='atomTest',schemaName='atom',schemaRegistry=schemaRegistry)\n",
    "    pprint(atoms)\n",
    "    atoms._allocate(size=10)\n",
    "    atoms.identity.element='C'\n",
    "    print(atoms.identity.element)\n",
    "    print(atoms[1].identity.atomicNumber)\n",
    "    # atoms[2].identity.atomicNumber=33\n",
    "    atoms[0].properties.topology.position=(1,2,3)*u.nm\n",
    "    atoms.properties.topology.velocity=(24,5,77)*u.m/u.s\n",
    "    print(atoms.properties.topology.position)\n",
    "    print(atoms.properties.topology.velocity)\n",
    "    print(dir(atoms.properties))\n",
    " \n",
    "# test h5py\n",
    "with h5py.File('/tmp/test-mol.h5','w') as h5:\n",
    "    # grp=\n",
    "    mols=Hdf5DataProxy(group=h5['/'],name='molTest',schemaName='molecule',schemaRegistry=schemaRegistry)\n",
    "    pprint(mols)\n",
    "    mols._allocate(size=10)\n",
    "    mols.identity.molecularWeight=1*u.yg\n",
    "    aa=mols[9].atoms\n",
    "    aa._allocate(size=500)\n",
    "    aa.properties.topology.position=(1,2,3)*u.nm\n",
    "    aa.properties.topology.velocity=(24,5,77)*u.m/u.s\n",
    "    print(mols.identity.molecularWeight)\n",
    "    print(aa.properties.topology.position)\n",
    "    print(aa.properties.topology.velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 5 grains.\n",
      "Grain <__main__.Hdf5DataProxy object at 0x7f72a086be20> has 8 molecules\n",
      "Grain <__main__.Hdf5DataProxy object at 0x7f72a086b790> has 12 molecules\n",
      "Grain <__main__.Hdf5DataProxy object at 0x7f72a08a3d60> has 32 molecules\n",
      "Grain <__main__.Hdf5DataProxy object at 0x7f72a3d22c70> has 40 molecules\n",
      "Grain <__main__.Hdf5DataProxy object at 0x7f72bc4322b0> has 42 molecules\n",
      "1723 atoms created in 7.68332576751709 (224.252/sec).\n"
     ]
    }
   ],
   "source": [
    "# test h5py\n",
    "import time, random\n",
    "t0=time.time()\n",
    "atomCounter=0\n",
    "with h5py.File('/tmp/test-grain.h5','w') as h5:\n",
    "    grp=h5.require_group('grains')\n",
    "    grains=Hdf5DataProxy(group=grp,name='grains',schemaName='grain',schemaRegistry=schemaRegistry)\n",
    "    grains._allocate(size=5)\n",
    "    print(f\"There is {len(grains)} grains.\")\n",
    "    for g in grains:\n",
    "        g.molecules._allocate(size=random.randint(5,50))\n",
    "        print(f\"Grain {g} has {len(g.molecules)} molecules\")\n",
    "        for m in g.molecules:\n",
    "            m.identity.molecularWeight=random.randint(1,10)*u.yg\n",
    "            m.atoms._allocate(size=random.randint(5,20))\n",
    "            for a in m.atoms:\n",
    "                a.identity.element=random.choice('ABCDEFGHI')\n",
    "                a.properties.topology.position=(1,2,3)*u.nm\n",
    "                a.properties.topology.velocity=(24,5,77)*u.m/u.s\n",
    "                # not yet, see https://stackoverflow.com/q/67192725/761090\n",
    "                # a.properties.topology.structure=[1,2,3] # np.array([random.randint(1,20) for i in range(random.randint(5,20))],dtype='l')\n",
    "                atomCounter+=1\n",
    "t1=time.time()\n",
    "print(f'{atomCounter} atoms created in {t1-t0} ({atomCounter/(t1-t0):g}/sec).')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot change data-type for object array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-4ad8f6d87c6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# does not write the value back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# does not write the value back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Cannot change data-type for object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Cannot change data-type for object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp\u001b[0m \u001b[0;31m# Cannot change data-type for object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, args, val)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcast_compound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/numpy/core/_internal.py\u001b[0m in \u001b[0;36m_view_is_safe\u001b[0;34m(oldtype, newtype)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnewtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasobject\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0moldtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot change data-type for object array.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot change data-type for object array."
     ]
    }
   ],
   "source": [
    "with h5py.File('/tmp/test-vla.h5','w') as h5:\n",
    "    dt=np.dtype([('a',h5py.vlen_dtype(np.dtype('int32')))])\n",
    "    dset=h5.create_dataset('test',(5,),dtype=dt)\n",
    "    dset['a'][2]=[1,2,3] # does not write the value back\n",
    "    dset[2]['a']=[1,2,3] # does not write the value back\n",
    "    dset['a',2]=[1,2,3]  # Cannot change data-type for object array\n",
    "    dset[2,'a']=[1,2,3]  # Cannot change data-type for object array\n",
    "    tmp=dset['a']; tmp[2]=[1,2,3]; dset['a']=tmp # Cannot change data-type for object array\n",
    "    tmp=dset[2]; tmp['a']=[1,2,3]; dset[2]=tmp # 'list' object has no attribute 'dtype'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
